---
title: 'Outliers and Other Fragmented Works'
author: ' '
date: '2020-03-16'
slug: march_works
---

Practice builds experience. A few weeks ago, I finished several very fragmented works, which needs to be summerized.
First is outliers detection. Until joining in [House Prediction Competiton](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview) did I realized how important outliers handling is! At first I recode outliers (I define *outliers* by histogram) to a high quantile. I gradually found this is wrong. It will generate accumulation of special values. Then, it does no good to prediction. I posted [this question](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/132754#765810) and read others tutorial notebooks. I found using binary distibution plot (scatter plot) is helpful. Those points who are opposite to main distribution should be dropped. It really improve my LB ranking.

However, there's no free lunch, dropping samples will cause sample size reduction. The first method will not lose samples. This is a trade-off. Another way for tackling outliers is [IsolationForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html), but I haven't tried it.

---

A [post](http://www.win-vector.com/blog/2013/05/bayesian-and-frequentist-approaches-ask-the-right-question/) written by Nina Zumel focuses on Bayesian approach is really easy to understand. It introduce a simple framework of Bayesian inference. Although the data is simple, it reminds me that 

> Common statistical tests are linear models

written by [Jonas Kristoffer Lindel√∏v](https://lindeloev.github.io/tests-as-linear/). The simple framework could be generilzed to regression analysis. 


---


Some papers written by big professors not teaching you technic, but improve your *data IQ*. The first one is *Statistical Modeling: The Two Cultures* by Leo Brieman. Others could be found at [this article](https://cosx.org/2020/03/what-it-creates-is-natural-ds-ai-development/)'s reference list. Those papers are great help to my thesis.

---

After finishing a text classification task (a semi-intern), I found it's important to make columns 1:1 corresponding between train set and test set, or the result will be totally messed up. I write this:

```python
def consist_train_test(test):
    '''
    make test set columns corresponding to train set
    '''
    new_df = pd.DataFrame()
    for i in train_col: # train_col = train.columns
        if i in test.columns:
            new_df[i] = test[i]
        else:
            new_df[i] = 0
    new_df.fillna(0, inplace = True)
    order = train_col
    new_df[order] # order data
    return new_df
```

This actually a practical trick. Some algorithms will throw an error if you don't do this. Similarly, I solved this problem at my [shiny app](https://xiaosong.shinyapps.io/spam_text/).





