<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <base target="_blank">
    <meta name="baidu-site-verification" content="XQ7m1PA0VK" />
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.64.0" />


<title>Keras入门示范 - 宋骁</title>
<meta property="og:title" content="Keras入门示范 - 宋骁">


  <link href='../../favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../../css/fonts.css" media="all">
<link rel="stylesheet" href="../../css/main.css" media="all">



  </head>
  <body>
    <div class="fixed-top">
      <header class="header">
        <nav class="nav">
  <a href="../../" class="nav-logo">
    <img src="../../images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../../">首页</a></li>
    
    <li><a href="../../zh/zhresume/">简历</a></li>
    
    <li><a href="../../zh/post/">文章</a></li>
    
    <li><a href="https://www.kaggle.com/rikdifos">Kaggle</a></li>
    
    <li><a href="https://github.com/songxxiao">Github</a></li>
    
    <li><a href="../../en">English</a></li>
    
  </ul>
</nav>
      </header>

<link rel="stylesheet">

<main class="content" role="main">

  <article class="article">

    <h1 class="article-title">Keras入门示范</h1>

    
    <span class="article-date">2020-05-16</span>
    

    <div class="article-content">
      


<p>Xiao Song</p>
<p><a href="https://xsong.ltd/" class="uri">https://xsong.ltd/</a></p>
<p>As a beginner, it’s necessary to write some simple guides using simple data.</p>
<pre class="python"><code>import numpy as np 
import pandas as pd

X_train = pd.read_csv(&#39;E:/some_code/py_basic/house_price/data/train1.csv&#39;) # prepare data
X_test = pd.read_csv(&#39;E:/some_code/py_basic/house_price/data/test1.csv&#39;)

Y_train = np.array(X_train[&#39;SalePrice&#39;])
Y_train = np.log1p(Y_train)

X_train.drop([&#39;SalePrice&#39;],axis = 1, inplace = True)</code></pre>
<pre class="python"><code>Y_train
#&gt; array([12.24769912, 12.10901644, 12.31717117, ..., 12.25486757,
#&gt;        12.49313327, 11.86446927])</code></pre>
<pre class="python"><code>X_train.shape
#&gt; (1436, 109)</code></pre>
<pre class="python"><code>X_test.shape
#&gt; (1459, 109)</code></pre>
<div id="feature-standardization" class="section level1">
<h1>Feature Standardization</h1>
<p>Standardize features by removing the mean and scaling to unit variance:
<span class="math display">\[z = {{x - u} \over s}\]</span></p>
<p><span class="math inline">\(z\)</span> is standardize feature of <span class="math inline">\(x\)</span>, u is the mean of <span class="math inline">\(x\)</span>, and <span class="math inline">\(s\)</span> is the standard deviation of <span class="math inline">\(x\)</span>.</p>
<pre class="python"><code>#from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import StandardScaler

def standardize(df):
    &#39;&#39;&#39;standardize features&#39;&#39;&#39;
    transformer = StandardScaler().fit(df) 
    newX = transformer.transform(df)
    X = pd.DataFrame(newX,columns = df.columns)
    return X

X_train = standardize(X_train) # X train
X_test = standardize(X_test) </code></pre>
<pre class="python"><code>X_train
#&gt;       MSSubClass  MSZoningRM  ...  SaleTypeWD  SaleConditionOth
#&gt; 0       0.074674   -0.517138  ...    0.389312         -0.465778
#&gt; 1      -0.874282   -0.517138  ...    0.389312         -0.465778
#&gt; 2       0.074674   -0.517138  ...    0.389312         -0.465778
#&gt; 3       0.311913   -0.517138  ...    0.389312          2.146946
#&gt; 4       0.074674   -0.517138  ...    0.389312         -0.465778
#&gt; ...          ...         ...  ...         ...               ...
#&gt; 1431   -0.874282    1.933720  ...    0.389312         -0.465778
#&gt; 1432    0.074674   -0.517138  ...    0.389312         -0.465778
#&gt; 1433   -0.874282   -0.517138  ...    0.389312         -0.465778
#&gt; 1434    0.311913   -0.517138  ...    0.389312         -0.465778
#&gt; 1435   -0.874282   -0.517138  ...    0.389312         -0.465778
#&gt; 
#&gt; [1436 rows x 109 columns]</code></pre>
<pre class="python"><code>X_train.describe()
#&gt;          MSSubClass    MSZoningRM  ...    SaleTypeWD  SaleConditionOth
#&gt; count  1.436000e+03  1.436000e+03  ...  1.436000e+03      1.436000e+03
#&gt; mean  -5.721205e-17  3.101821e-16  ... -3.223203e-16     -1.622039e-16
#&gt; std    1.000348e+00  1.000348e+00  ...  1.000348e+00      1.000348e+00
#&gt; min   -8.742817e-01 -5.171379e-01  ... -2.568635e+00     -4.657780e-01
#&gt; 25%   -8.742817e-01 -5.171379e-01  ...  3.893119e-01     -4.657780e-01
#&gt; 50%   -1.625649e-01 -5.171379e-01  ...  3.893119e-01     -4.657780e-01
#&gt; 75%    3.119131e-01 -5.171379e-01  ...  3.893119e-01     -4.657780e-01
#&gt; max    3.158781e+00  1.933720e+00  ...  3.893119e-01      2.146946e+00
#&gt; 
#&gt; [8 rows x 109 columns]</code></pre>
<pre class="python"><code>X_train.shape[1]
#&gt; 109</code></pre>
</div>
<div id="neural-network-building" class="section level1">
<h1>Neural Network Building</h1>
<pre class="python"><code>from keras import models
#&gt; Using TensorFlow backend.
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_quint8 = np.dtype([(&quot;quint8&quot;, np.uint8, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_qint16 = np.dtype([(&quot;qint16&quot;, np.int16, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_quint16 = np.dtype([(&quot;quint16&quot;, np.uint16, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_qint32 = np.dtype([(&quot;qint32&quot;, np.int32, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   np_resource = np.dtype([(&quot;resource&quot;, np.ubyte, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_quint8 = np.dtype([(&quot;quint8&quot;, np.uint8, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_qint16 = np.dtype([(&quot;qint16&quot;, np.int16, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_quint16 = np.dtype([(&quot;quint16&quot;, np.uint16, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   _np_qint32 = np.dtype([(&quot;qint32&quot;, np.int32, 1)])
#&gt; C:\ProgramData\Anaconda3\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
#&gt;   np_resource = np.dtype([(&quot;resource&quot;, np.ubyte, 1)])
from keras import layers

model = models.Sequential()
model.add(layers.Dense(64, activation=&#39;relu&#39;,input_shape=(X_train.shape[1],)))
model.add(layers.Dense(64, activation=&#39;relu&#39;))
model.add(layers.Dense(1))

model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;mse&#39;, metrics=[&#39;mae&#39;])
model.summary()
#&gt; Model: &quot;sequential_1&quot;
#&gt; _________________________________________________________________
#&gt; Layer (type)                 Output Shape              Param #   
#&gt; =================================================================
#&gt; dense_1 (Dense)              (None, 64)                7040      
#&gt; _________________________________________________________________
#&gt; dense_2 (Dense)              (None, 64)                4160      
#&gt; _________________________________________________________________
#&gt; dense_3 (Dense)              (None, 1)                 65        
#&gt; =================================================================
#&gt; Total params: 11,265
#&gt; Trainable params: 11,265
#&gt; Non-trainable params: 0
#&gt; _________________________________________________________________</code></pre>
<pre class="python"><code>#?models.Sequential.fit</code></pre>
<pre class="python"><code>model.fit(X_train,Y_train,
    epochs = 20, # Number of epochs to train the model
    batch_size = 512) # Number of samples per gradient update.
#&gt; Epoch 1/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 140.8267 - mae: 11.8557
#&gt; 1436/1436 [==============================] - 0s 117us/step - loss: 129.9364 - mae: 11.3778
#&gt; Epoch 2/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 110.2607 - mae: 10.4750
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 104.7116 - mae: 10.2016
#&gt; Epoch 3/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 92.1465 - mae: 9.5612
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 86.7293 - mae: 9.2574
#&gt; Epoch 4/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 76.0077 - mae: 8.6382
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 71.0038 - mae: 8.3401
#&gt; Epoch 5/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 61.2461 - mae: 7.7208
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 56.7937 - mae: 7.4047
#&gt; Epoch 6/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 47.9284 - mae: 6.7730
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 44.1101 - mae: 6.4494
#&gt; Epoch 7/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 36.3466 - mae: 5.7926
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 33.1786 - mae: 5.4922
#&gt; Epoch 8/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 26.6782 - mae: 4.8259
#&gt; 1436/1436 [==============================] - 0s 7us/step - loss: 24.1637 - mae: 4.5638
#&gt; Epoch 9/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 18.7983 - mae: 3.9653
#&gt; 1436/1436 [==============================] - 0s 15us/step - loss: 17.1082 - mae: 3.7223
#&gt; Epoch 10/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 13.0147 - mae: 3.1449
#&gt; 1436/1436 [==============================] - 0s 10us/step - loss: 11.9347 - mae: 3.0062
#&gt; Epoch 11/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 9.0378 - mae: 2.5687
#&gt; 1436/1436 [==============================] - 0s 7us/step - loss: 8.4068 - mae: 2.4534
#&gt; Epoch 12/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 6.7916 - mae: 2.1759
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 6.1296 - mae: 2.0493
#&gt; Epoch 13/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 4.7825 - mae: 1.7972
#&gt; 1436/1436 [==============================] - 0s 7us/step - loss: 4.7077 - mae: 1.7736
#&gt; Epoch 14/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 3.6850 - mae: 1.5244
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 3.7788 - mae: 1.5663
#&gt; Epoch 15/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 3.5174 - mae: 1.5397
#&gt; 1436/1436 [==============================] - 0s 5us/step - loss: 3.1474 - mae: 1.4160
#&gt; Epoch 16/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 2.8935 - mae: 1.3455
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 2.6860 - mae: 1.2970
#&gt; Epoch 17/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 2.7045 - mae: 1.2770
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 2.3342 - mae: 1.2015
#&gt; Epoch 18/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 2.1927 - mae: 1.1505
#&gt; 1436/1436 [==============================] - 0s 5us/step - loss: 2.0556 - mae: 1.1234
#&gt; Epoch 19/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 1.8730 - mae: 1.0689
#&gt; 1436/1436 [==============================] - 0s 6us/step - loss: 1.8298 - mae: 1.0558
#&gt; Epoch 20/20
#&gt; 
#&gt;  512/1436 [=========&gt;....................] - ETA: 0s - loss: 1.7306 - mae: 1.0407
#&gt; 1436/1436 [==============================] - 0s 5us/step - loss: 1.6410 - mae: 1.0003
#&gt; &lt;keras.callbacks.callbacks.History object at 0x0000000059D72BA8&gt;
#&gt; 
#&gt; WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.</code></pre>
</div>
<div id="validation-data" class="section level1">
<h1>Validation data</h1>
<p>first I create validation set:</p>
<pre class="python"><code>x_val = X_train[:1000]
partial_x_train = X_train[1000:]
y_val = Y_train[:1000]
partial_y_train = Y_train[1000:]</code></pre>
<pre class="python"><code>history = model.fit(partial_x_train,partial_y_train,
    epochs=20,
    batch_size=512,
    validation_data=(x_val, y_val))
#&gt; Train on 436 samples, validate on 1000 samples
#&gt; Epoch 1/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 82us/step - loss: 1.4079 - mae: 0.9290 - val_loss: 1.5265 - val_mae: 0.9630
#&gt; Epoch 2/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 16us/step - loss: 1.3039 - mae: 0.8974 - val_loss: 1.5112 - val_mae: 0.9572
#&gt; Epoch 3/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 1.2203 - mae: 0.8690 - val_loss: 1.4958 - val_mae: 0.9513
#&gt; Epoch 4/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 1.1471 - mae: 0.8430 - val_loss: 1.4811 - val_mae: 0.9456
#&gt; Epoch 5/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 16us/step - loss: 1.0817 - mae: 0.8199 - val_loss: 1.4671 - val_mae: 0.9401
#&gt; Epoch 6/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 1.0222 - mae: 0.7980 - val_loss: 1.4540 - val_mae: 0.9351
#&gt; Epoch 7/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.9677 - mae: 0.7771 - val_loss: 1.4416 - val_mae: 0.9302
#&gt; Epoch 8/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 11us/step - loss: 0.9172 - mae: 0.7570 - val_loss: 1.4297 - val_mae: 0.9253
#&gt; Epoch 9/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 11us/step - loss: 0.8702 - mae: 0.7382 - val_loss: 1.4180 - val_mae: 0.9203
#&gt; Epoch 10/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.8262 - mae: 0.7199 - val_loss: 1.4068 - val_mae: 0.9157
#&gt; Epoch 11/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 11us/step - loss: 0.7848 - mae: 0.7020 - val_loss: 1.3959 - val_mae: 0.9111
#&gt; Epoch 12/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.7456 - mae: 0.6848 - val_loss: 1.3855 - val_mae: 0.9066
#&gt; Epoch 13/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.7084 - mae: 0.6678 - val_loss: 1.3750 - val_mae: 0.9022
#&gt; Epoch 14/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.6728 - mae: 0.6511 - val_loss: 1.3649 - val_mae: 0.8981
#&gt; Epoch 15/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.6390 - mae: 0.6349 - val_loss: 1.3549 - val_mae: 0.8939
#&gt; Epoch 16/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 11us/step - loss: 0.6068 - mae: 0.6190 - val_loss: 1.3454 - val_mae: 0.8899
#&gt; Epoch 17/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 11us/step - loss: 0.5759 - mae: 0.6035 - val_loss: 1.3358 - val_mae: 0.8861
#&gt; Epoch 18/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.5463 - mae: 0.5884 - val_loss: 1.3266 - val_mae: 0.8824
#&gt; Epoch 19/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.5181 - mae: 0.5735 - val_loss: 1.3176 - val_mae: 0.8789
#&gt; Epoch 20/20
#&gt; 
#&gt; 436/436 [==============================] - 0s 14us/step - loss: 0.4910 - mae: 0.5590 - val_loss: 1.3087 - val_mae: 0.8755</code></pre>
<p>Extract cross validation information:</p>
<pre class="python"><code>history_dict = history.history
loss_values = history_dict[&#39;loss&#39;]
val_loss_values = history_dict[&#39;val_loss&#39;]
epochs = range(1, len(loss_values) + 1)
cv_info = pd.DataFrame({&#39;epochs&#39;:epochs,&#39;loss_values&#39;:loss_values,&#39;val_loss_values&#39;:val_loss_values})  </code></pre>
<pre class="python"><code>cv_info
#&gt;     epochs  loss_values  val_loss_values
#&gt; 0        1     1.407855         1.526466
#&gt; 1        2     1.303904         1.511185
#&gt; 2        3     1.220280         1.495771
#&gt; 3        4     1.147146         1.481092
#&gt; 4        5     1.081681         1.467129
#&gt; 5        6     1.022173         1.454036
#&gt; 6        7     0.967678         1.441625
#&gt; 7        8     0.917171         1.429717
#&gt; 8        9     0.870244         1.417997
#&gt; 9       10     0.826236         1.406838
#&gt; 10      11     0.784827         1.395922
#&gt; 11      12     0.745629         1.385457
#&gt; 12      13     0.708371         1.374981
#&gt; 13      14     0.672793         1.364876
#&gt; 14      15     0.639036         1.354943
#&gt; 15      16     0.606813         1.345370
#&gt; 16      17     0.575905         1.335776
#&gt; 17      18     0.546300         1.326586
#&gt; 18      19     0.518076         1.317633
#&gt; 19      20     0.490982         1.308668</code></pre>
<pre class="python"><code>cv_info = pd.melt(cv_info, id_vars=[&#39;epochs&#39;], value_vars=[&#39;loss_values&#39;, &#39;val_loss_values&#39;]) </code></pre>
<pre class="python"><code>from plotnine import *

(
ggplot(cv_info,aes(&#39;epochs&#39;,&#39;value&#39;,color = &#39;variable&#39;)) +
geom_line() +
geom_point()
)
#&gt; &lt;ggplot: (-9223372036742088048)&gt;</code></pre>
<p><img src="../../post/keras_example_files/figure-html/unnamed-chunk-17-1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="prediction" class="section level1">
<h1>Prediction</h1>
<pre class="python"><code>Y_pred = model.predict(X_test)
Y_pred
#&gt; array([[12.338795 ],
#&gt;        [11.667165 ],
#&gt;        [12.356974 ],
#&gt;        ...,
#&gt;        [ 9.942007 ],
#&gt;        [10.448301 ],
#&gt;        [12.4071245]], dtype=float32)</code></pre>
<pre class="python"><code>Y_pred.shape
#&gt; (1459, 1)</code></pre>
<pre class="python"><code>Y_pred = np.concatenate(Y_pred).ravel() # to flatten 2 dimition array
Y_pred = np.expm1(Y_pred)
Y_pred
#&gt; array([228385.52 , 116676.01 , 232575.31 , ...,  20784.42 ,  34484.746,
#&gt;        244536.64 ], dtype=float32)</code></pre>
<pre class="python"><code>test = pd.read_csv(&#39;E:/some_code/py_basic/house_price/data/test.csv&#39;)
submission = pd.DataFrame({&#39;id&#39;: test[&#39;Id&#39;], &#39;SalePrice&#39;: Y_pred})
submission.head(10)
#&gt;      id      SalePrice
#&gt; 0  1461  228385.515625
#&gt; 1  1462  116676.007812
#&gt; 2  1463  232575.312500
#&gt; 3  1464  269194.937500
#&gt; 4  1465   54343.210938
#&gt; 5  1466  141306.156250
#&gt; 6  1467  137139.875000
#&gt; 7  1468  533446.875000
#&gt; 8  1469    8107.077637
#&gt; 9  1470  915192.312500</code></pre>
<pre class="python"><code>#submission.to_csv(&#39;./output/keras.csv&#39;,index = False) # save result</code></pre>
</div>

    </div>
  </article>

  


<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//Xiao Song.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


<div id="disqus_thread"></div>
<script>





(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://xiao-song.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  <center>
   <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=1660be&w=180&t=n&d=bLbRVCl6hpPrG3ydeBPnss5Icv_ZJXbokniqNe34m4M&co=f1f3ec&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
  </center>

<footer class="footer">
        <ul class="footer-links">
            <a href="https://github.com/songxxiao" class="footer-links-kudos"> <img src="../../images/git.svg" alt=" " width="15" height="15"></a>
            <a href="https://www.linkedin.com/in/xiao-song-a1ab5318b/" class="footer-links-kudos"> <img src="../../images/linkedin.svg" alt=" " width="15" height="15"></a>
            <a href="https://www.kaggle.com/rikdifos" class="footer-links-kudos"> <img src="../../images/kaggle.png" alt=" " width="15.2" height="14.5"></a>
            <a href="../../archives/subscribe" class="footer-links-kudos"> <img src="../../images/rss.svg" alt=" " width="14.5" height="15"></a>
        </ul>
</footer>


</main>

  <center>
   <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=1660be&w=180&t=n&d=bLbRVCl6hpPrG3ydeBPnss5Icv_ZJXbokniqNe34m4M&co=f1f3ec&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
  </center>

<footer class="footer">

      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-144652310-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  </body>
</html>