<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.55.5" />


<title>初中生学习成绩的影响因素: 基于分类与回归树的分析 - Xiao Song </title>
<meta property="og:title" content="初中生学习成绩的影响因素: 基于分类与回归树的分析 - Xiao Song ">


  <link href='../favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../css/fonts.css" media="all">
<link rel="stylesheet" href="../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../" class="nav-logo">
    <img src="../images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../">Home</a></li>
    
    <li><a href="../englishresume/">Resume</a></li>
    
    <li><a href="../chnresume/">Chinese Resume</a></li>
    
    <li><a href="https://github.com/ECSTA7Y">GitHub</a></li>
    
    <li><a href="../reward/">Reward</a></li>
    
  </ul>
</nav>

      </header>

<link rel="stylesheet">

<main class="content" role="main">

  <article class="article">

    <h1 class="article-title">初中生学习成绩的影响因素: 基于分类与回归树的分析</h1>

    
    <span class="article-date">2019-06-30</span>
    

    <div class="article-content">
      


<div class="section level2">
<h2>数据</h2>
<p>本文采用<a href="https://ceps.ruc.edu.cn/">中国教育追踪调查</a> (China Education Panel Survey, CEPS)2013-2014学年基线数据。 采用PPS抽样方法，以人口平均受教育水平和人口比例为分层变量并通过两阶段分层抽样从从全国随机抽取了28个县级单位作为调查点。具体而言，CEPS在每个入样县（区）所辖地理范围内分别抽取4所初中学校。并在每所入样学校中分别抽取4个班级，包括2个七年级班和2个九年级班。</p>
</div>
<div class="section level2">
<h2>模型与算法</h2>
<p>CART算法全称为分类与回归树（Classification and Regression Trees）。它可以处理分类与回归算法，以及生存分析因变量。作为一种非参数的机器学习方法，CART决策树无需对数据的分布做任何假定。CART算法划分数据的依据是变量的取值顺序，因此它对异常值不敏感。最后，通过交叉验证（Cross Validation）的方法求得预测误差。 回归树模型可表示为： <span class="math display">\[f(x) = \sum\limits_{m = 1}^M {{c_m}I(x \in {R_m})} \]</span></p>
<p>其中，<span class="math inline">\(x\)</span>是一系列输入特征（自变量），<span class="math inline">\({R_1},{R_2},...,{R_m}\)</span>是输入空间被划分的M个区域。 是区域<span class="math inline">\({R_m}\)</span>对应的最优值。<span class="math inline">\(I\)</span>代表的是指示函数（indicator function），当输入变量<span class="math inline">\(x\)</span>属于区域 <span class="math inline">\({R_m}\)</span>时，输出为1，否则输出为0。 CART算法选择基尼系数进行属性划分。CART算法可以运用于分类和回归问题中。</p>
<p>为了防止过拟合问题(Over-fitted),需要对过于复杂的树模型进行剪枝。这也是训练模型的重要过程。通过改善模型的复杂度参数(Complexity Parameter, CP)。在CART算法中，复杂度参数定义如下：</p>
<p><span class="math display">\[{{\rm{C}}_\alpha }(T) = C(T) + \alpha \left| T \right|\]</span></p>
<p>其中，<span class="math inline">\(T\)</span>为任意子树。<span class="math inline">\(C(T)\)</span>为对训练数据的预测误差（如基尼指数）， <span class="math inline">\(\left| T \right|\)</span>为子树的叶结点个数，<span class="math inline">\(\alpha \ge 0\)</span>为参数，<span class="math inline">\({{\rm{C}}_\alpha }(T)\)</span>是参数为<span class="math inline">\(\alpha\)</span>时的子树<span class="math inline">\(T\)</span>的整体损失。参数<span class="math inline">\(\alpha\)</span>测量了模型的复杂度。</p>
</div>
<div class="section level2">
<h2>变量</h2>
<p>本研究依据以往教育学和社会学文献，选取了50个自变量进行预测。为了降低测量误差，本研究在变量选取的过程中遵循了以下两个原则：1.尽可能挑选“客观的”变量。2.尽可能挑选直观上对学习成绩有重要影响的变量。</p>
<div class="section level3">
<h3>因变量</h3>
<p>本研究的因变量是被调查学生上一次期中考试的成绩。包括数学成绩、语文成绩、英语成绩。我们将同时对总成绩进行分析。</p>
<p>为了讨论学习成绩的门槛效应，我们将数学成绩是否位于所有学生的前25%(是=1，否=0)单独划分为一个分类变量建立分类树。下图展示了标准化总成绩的密度直方图估计。箱线图展示了我们抽取的30所学校的数学原始成绩差异。我们可以发现，标准化总成绩基本上呈现了正态分布。不同学校间的数学成绩差异十分显著。</p>
</div>
<div class="section level3">
<h3>自变量</h3>
<p>下面展示了自变量以及自变量在模型中的编码：</p>
<p>家庭变量：每星期零用钱(money)、上兴趣班费用总计(clfee)、监督孩子的作业(qianzi)、花在孩子身上的时间(lifetm)、孩子交流方言(dial)、父母交流方言(chidia)、家长教育期望(eduyexp)、对孩子未来的信心(futcfd)、孩子户口类型(huko)、家长教育程度(eduy)、家长政治面貌(dangy)、住房是否生产经营用(houspro)。</p>
<p>个人变量：性别(sex)、是否独生子女(onechi)、父亲教育水平(faedu)、母亲教育水平(maedu)、爸爸经常酗酒(drunk)、父母经常吵架(qurel)、父母之间关系很好(relation)、有独立书桌(desk)、家里有电脑和网络(net)、家庭交流方言(dialect)、父母督促学习天数(chkhmwk chkcouse)、父母教育期望(eduexp)。</p>
<p>学校变量：学校性质(schtype)、教室数量(schcsrm)、学校电脑数(comno)、图书数量(bknum)、生均财政拨款(buget)、持有教师资格证人数(eduqua)、打架斗殴(fight)、破坏公物(brkpb)、吸烟(smok)、饮酒(drink)、高级教师年收入(teainc)。</p>
<p>班级变量：教师总课时(classtm)、 备课时间(clpre)、批改作业时间(revitm)、班主任教授本班科目(subject)、认识多少家长(know)、是否有抽烟喝酒的学生(drsmok)、与学生交流时间(commhr)。</p>
<div class="figure" style="text-align: center"><span id="fig:bust"></span>
<img src="../post/edutree_files/figure-html/bust-1.png" alt="标准化总成绩的直方图" width="100%" />
<p class="caption">
Figure 1: 标准化总成绩的直方图
</p>
</div>
<p>为了直观地描述不同学校与学习成绩的差异，图2展示了以学校为分组变量，原始数学成绩为因变量的箱线图。</p>
<pre class="r"><code>setwd(&quot;E:/edu/data2&quot;)
ceps &lt;- read_dta(&quot;E:/edu/data2/ceps.dta&quot;)
#抽出30所学校，作成绩箱线图
ceps1 &lt;- ceps %&gt;% 
group_by(schids) %&gt;% 
summarize(mathmean = mean(tr_mat, na.rm = T))
set.seed(2019)
sample &lt;- sample(1:nrow(ceps1),30,replace = F)#随机抽取30个学校
ceps1 &lt;- ceps1[sample,]
ceps1 &lt;- ceps1$schids #提取抽中学校编号的向量
delte &lt;- subset(ceps,schids == ceps1[1])
#遍历抽中的学校id，纵向合并数据框
for (i in ceps1) delte &lt;- rbind(delte, subset(ceps,schids == i)) 
#箱线图
delte$schids &lt;- as.factor(delte$schids)  
ggplot(delte, aes(schids,tr_mat)) + 
  geom_boxplot(size=0.1) +
  xlab(&#39;学校代码&#39;) + ylab(&#39;数学原始成绩&#39;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:a"></span>
<img src="../post/edutree_files/figure-html/a-1.png" alt="随机抽取30所学校的数学成绩差异" width="100%" />
<p class="caption">
Figure 2: 随机抽取30所学校的数学成绩差异
</p>
</div>
<pre class="r"><code>#ceps1 &lt;- subset(ceps,schids&lt;=30)

ceps &lt;- lapply(ceps, unclass)
ceps &lt;- data.frame(ceps)</code></pre>
</div>
</div>
<div class="section level2">
<h2>分析结果</h2>
<div class="section level3">
<h3>回归树</h3>
<p>首先我们将展示总成绩的回归结果。由于七年级和九年级学生考试总分的不同。我们将九年级子样本单独进行分析。</p>
<pre class="r"><code>cont &lt;- rpart.control(minsplit=5,maxcompete=100,xval=10,maxdepth=30,cp=0.01)
tree &lt;- rpart(sdtotal ~ schids + sex + onechi +  maedu +  faedu + drunk + qurel + relation +  desk + net + dialect + chkhmwk + chkcouse + classtm +  clpre + revitm + subject + know + drsmok + commhr + schtype + schcsrm +  comno +  bknum + buget +  eduqua + fight + brkpb + smok +  drink +  teainc + money + clfee + qianzi + lifetm +  dial +  chidia +  futcfd +  huko + eduy +  dangy +  houspro ,data = subset(ceps,grade9 == 1),weights = sweight,method = &quot;anova&quot;,parms = list(split=&quot;gini&quot;),control=cont,na.action = na.omit)</code></pre>
<pre class="r"><code>tree$cptable #复杂度参数表</code></pre>
<pre><code>          CP nsplit rel error    xerror         xstd
1 0.07468185      0 1.0000000 1.0008194 0.0005634699
2 0.03717668      1 0.9253181 0.9281575 0.0005277763
3 0.01820999      2 0.8881415 0.9108954 0.0005315458
4 0.01328867      3 0.8699315 0.9052528 0.0005502155
5 0.01308371      4 0.8566428 0.8989148 0.0005484642
6 0.01281814      5 0.8435591 0.8989148 0.0005484642
7 0.01000000      6 0.8307410 0.8843597 0.0005490267</code></pre>
<pre class="r"><code>rpart.plot(tree)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:sfff"></span>
<img src="../post/edutree_files/figure-html/sfff-1.png" alt="总成绩的回归树" width="100%" />
<p class="caption">
Figure 3: 总成绩的回归树
</p>
</div>
<p>下面展示的是数学原始成绩是否位于前25%的分类决策树。首先，我们在备选的约50个自变量中纳入学校哑变量。仅考虑家庭、个体、班级因素对学生学习成绩的影响。通过划分训练集和测试集的方式计算模型的预测错误率。检验模型的泛化能力。</p>
<p><a href="https://www.jianshu.com/p/08c28c5c55a7">R语言表格教程</a></p>
<pre class="r"><code>set.seed(1212323) #设置随机数种子

#简单交叉验证划分测试集和训练集
sampled &lt;- sample(1:nrow(ceps),nrow(ceps)*0.3,replace=FALSE) #抽取30%样本作为验证集
test &lt;- ceps[sampled,] #测试集
train &lt;- ceps[-sampled,] #训练集

cont &lt;- rpart.control(minsplit=5,maxcompete=100,xval=10,maxdepth=30,cp=0.01) #设置参数

cltree3 &lt;- rpart(matgreat ~  schids + sex + onechi +  maedu +  faedu + drunk + qurel + relation + desk + net + dialect + chkhmwk + chkcouse + classtm +  clpre + revitm + subject + know + drsmok + commhr + schtype + schcsrm + comno +  bknum + buget + eduqua + fight + brkpb + smok +  drink +  teainc + money + clfee + qianzi + lifetm +  dial +  chidia +  futcfd +  huko + eduy +  dangy +  houspro ,
                 data = subset(train,grade9 == 1),weights = sweight,method = &quot;class&quot;,parms = list(split=&quot;gini&quot;),control=cont,na.action = na.omit,model=T) #决策树
#knitr::kable(printcp(cltree3),caption=&quot;复杂度参数表&quot;,digits =4)
rpart.plot(cltree3)</code></pre>
<div class="figure" style="text-align: center">
<img src="../post/edutree_files/figure-html/c%20-1.png" alt="未剪枝的分类树\label{fig3}" width="100%" />
<p class="caption">
(#fig:c )未剪枝的分类树
</p>
</div>
<pre class="r"><code>test &lt;- na.omit(test) #删除缺失值
y.pr &lt;- predict(cltree3,test,type=&quot;prob&quot;) #预测测试集概率

pr &lt;- y.pr[,2] 
test &lt;- cbind(test,pr)
modelroc &lt;- roc(test$matgreat,test$pr)
#ROC 曲线
#plot(modelroc, print.auc=T, auc.polygon=T, max.auc.polygon=TRUE,auc.polygon.col=&quot;skyblue&quot;, print.thres=TRUE,xlab =&#39;伪正类率&#39;,ylab=&#39;真正类率&#39;)

test$yhat &lt;- ifelse(test$pr &gt;0.5,&#39;1&#39;,&#39;0&#39;) #大于0.5设置为&quot;是&quot;
attach(test)
tab &lt;- table(yhat,matgreat) 
names(dimnames(tab))&lt;-c(&quot;预测值&quot;,&quot;真实值&quot;)
treeerror &lt;- (sum(tab)-sum(diag(tab)))/sum(tab)
tab</code></pre>
<pre><code>      真实值
预测值   0   1
     0 875 183
     1 138  85</code></pre>
<pre class="r"><code>treeerror #测试集错误率</code></pre>
<pre><code>[1] 0.2505855</code></pre>
<pre class="r"><code>cont &lt;- rpart.control(minsplit=5,maxcompete=100,xval=10,maxdepth=30,cp=0.014) #设置参数

cltree3 &lt;- rpart(matgreat ~  schids + sex + onechi +  maedu +  faedu + drunk + qurel + relation + desk + net + dialect + chkhmwk + chkcouse + classtm +  clpre + revitm + subject + know + drsmok + commhr + schtype + schcsrm + comno + bknum + buget + eduqua + fight + brkpb + smok +  drink +  teainc + money + clfee + qianzi + lifetm +  dial +  chidia +  futcfd + huko + eduy + dangy +  houspro ,
data = subset(train,grade9 == 1),weights = sweight,method = &quot;class&quot;,parms = list(split=&quot;gini&quot;),control=cont,na.action = na.omit) #决策树

#knitr::kable(printcp(cltree3),caption=&quot;复杂度参数表&quot;,digits =4)
cltree3$variable.importance #各个变量的重要性程度</code></pre>
<pre><code>     smok     bknum   classtm    eduqua     buget   subject    revitm 
92336.104 87082.851 72098.477 42822.536 37990.537 28371.716 26624.118 
   schids      know     fight     brkpb     comno    commhr     clpre 
25602.670 25452.345 23572.820 22293.765 21516.771 18454.934 16719.141 
   chidia   schcsrm    teainc   chkhmwk 
 9999.162  9588.660  2283.551  2032.974 </code></pre>
<pre class="r"><code>rpart.plot(cltree3)</code></pre>
<div class="figure" style="text-align: center">
<img src="../post/edutree_files/figure-html/d%20-1.png" alt="ROC曲线" width="100%" />
<p class="caption">
(#fig:d 1)ROC曲线
</p>
</div>
<pre class="r"><code>test &lt;- na.omit(test) #删除缺失值
y.pr &lt;- predict(cltree3,test,type=&quot;prob&quot;) #预测测试集概率

pr &lt;- y.pr[,2] 
test &lt;- cbind(test,pr)
modelroc &lt;- roc(test$matgreat,test$pr)
#auc(modelroc) #计算AUC值

#ROC 曲线
plot(modelroc, print.auc=T, auc.polygon=T, max.auc.polygon=TRUE,auc.polygon.col=&quot;skyblue&quot;, print.thres=TRUE,xlab =&#39;伪正类率&#39;,ylab=&#39;真正类率&#39;)</code></pre>
<div class="figure" style="text-align: center">
<img src="../post/edutree_files/figure-html/d%20-2.png" alt="ROC曲线" width="100%" />
<p class="caption">
(#fig:d 2)ROC曲线
</p>
</div>
<pre class="r"><code>#plot(modelroc,print.auc=T) 

test$yhat &lt;- ifelse(test$pr &gt;0.5,&#39;1&#39;,&#39;0&#39;) #大于0.5设置为&quot;是&quot;
attach(test)
tab &lt;- table(yhat,matgreat) 
treeerror &lt;- (sum(tab)-sum(diag(tab)))/sum(tab)
names(dimnames(tab))&lt;-c(&quot;预测值&quot;,&quot;真实值&quot;) #矩阵小标题
tab #混淆矩阵，行为测试集预测值，列为测试集观测值</code></pre>
<pre><code>      真实值
预测值   0   1
     0 875 183
     1 138  85</code></pre>
<pre class="r"><code>treeerror #测试集错误率</code></pre>
<pre><code>[1] 0.2505855</code></pre>
<p>可以发现，对因变量分类有显著贡献的变量有学校哑变量、对孩子未来的信心、上兴趣班费用总计、与学生交流时间。可见学校层面的特征对数学成绩的影响非常强。</p>
<p>在初次拟合分类树之后，我们对分类树进行剪枝。通过第一棵分类树的结果，我们选取预测误差(即表中的xerror通过交叉验证获得)最小的CP值带入到下一个模型中，最终的验证集错误率在25%左右。</p>
</div>
<div class="section level3">
<h3><a href="http://topepo.github.io/caret/train-models-by-tag.html#implicit-feature-selection">交叉验证</a></h3>
<p>使用<code>caret</code>包进行10次10折交叉验证,同样使用CART算法。</p>
<pre class="r"><code>library(caret)
#install.packages(&#39;e1071&#39;)
library(e1071)

ceps$matgreat &lt;- as.factor(ceps$matgreat)
ceps &lt;- na.omit(ceps)
#10次10折交叉验证
repeatedcv &lt;-trainControl(method =&quot;repeatedcv&quot;, number =10,repeats =10, savePredictions=TRUE)

 rpartFit &lt;- train(matgreat ~ schids + sex + onechi +  maedu +  faedu + drunk + qurel + relation + desk + net + dialect + chkhmwk + chkcouse + classtm +  clpre + revitm + subject + know + drsmok + commhr + schtype + schcsrm + comno + bknum + buget + eduqua + fight + brkpb + smok + drink + teainc + money + clfee + qianzi + lifetm +  dial +  chidia +  futcfd + huko + eduy + dangy +  houspro  ,
                    data = ceps,
                    method = &quot;rpart&quot;,
                    trControl = repeatedcv)
rpartFit</code></pre>
<pre><code>CART 

4519 samples
  42 predictor
   2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 
Summary of sample sizes: 4066, 4067, 4068, 4067, 4067, 4067, ... 
Resampling results across tuning parameters:

  cp          Accuracy   Kappa     
  0.03021442  0.8024365  0.28813163
  0.03638726  0.7938704  0.22949516
  0.07504873  0.7764993  0.07037779

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.03021442.</code></pre>
<pre class="r"><code>test &lt;- na.omit(ceps) #删除缺失值
y.pr &lt;- predict(rpartFit,ceps,type=&quot;prob&quot;) 
pr &lt;- y.pr[,2] 
ceps &lt;- cbind(ceps,pr)
modelroc &lt;- roc(ceps$matgreat,ceps$pr)

#ROC 曲线
plot(modelroc, print.auc=T, auc.polygon=T, max.auc.polygon=TRUE,auc.polygon.col=&quot;skyblue&quot;, print.thres=TRUE,xlab =&#39;伪正类率&#39;,ylab=&#39;真正类率&#39;)</code></pre>
<p><img src="../post/edutree_files/figure-html/caret-1.png" width="100%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ceps &lt;- within(ceps,{predc &lt;- predict(rpartFit); pr &lt;- predict(rpartFit,type=&quot;prob&quot;)})
tab &lt;- table(ceps$predc,ceps$matgreat)
treeerror &lt;- (sum(tab)-sum(diag(tab)))/sum(tab)
names(dimnames(tab))&lt;-c(&quot;预测值&quot;,&quot;真实值&quot;)
#混淆矩阵
tab</code></pre>
<pre><code>      真实值
预测值    0    1
     0 3295  639
     1  198  387</code></pre>
<pre class="r"><code>#错误率
treeerror</code></pre>
<pre><code>[1] 0.185218</code></pre>
<pre class="r"><code>plot(rpartFit)</code></pre>
<p><img src="../post/edutree_files/figure-html/caret-2.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div class="section level3">
<h3>随机森林</h3>
<pre class="r"><code>train$matgreat &lt;- as.factor(train$matgreat)
train &lt;- na.omit(train)
train &lt;- filter(train, is.na(matgreat)==F)

ratree &lt;- randomForest(matgreat ~ schids + sex + onechi +  maedu +  faedu + drunk + qurel + relation + desk + net + dialect + chkhmwk + chkcouse + classtm +  clpre + revitm + subject + know + drsmok + commhr + schtype + schcsrm + comno + bknum + buget + eduqua + fight + brkpb + smok + drink + teainc + money + clfee + qianzi + lifetm +  dial +  chidia +  futcfd + huko + eduy + dangy +  houspro  ,data = subset(train,grade9 == 1),importance=T,proximity=T,mtry=16)
ratree</code></pre>
<pre><code>
Call:
 randomForest(formula = matgreat ~ schids + sex + onechi + maedu +      faedu + drunk + qurel + relation + desk + net + dialect +      chkhmwk + chkcouse + classtm + clpre + revitm + subject +      know + drsmok + commhr + schtype + schcsrm + comno + bknum +      buget + eduqua + fight + brkpb + smok + drink + teainc +      money + clfee + qianzi + lifetm + dial + chidia + futcfd +      huko + eduy + dangy + houspro, data = subset(train, grade9 ==      1), importance = T, proximity = T, mtry = 16) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 16

        OOB estimate of  error rate: 21.6%
Confusion matrix:
    0   1 class.error
0 945 131   0.1217472
1 196 242   0.4474886</code></pre>
<pre class="r"><code>## 混淆矩阵
ratree$confusion</code></pre>
<pre><code>    0   1 class.error
0 945 131   0.1217472
1 196 242   0.4474886</code></pre>
<pre class="r"><code>#计算模型变量的重要性
importance(ratree, type=1, scale=T) </code></pre>
<pre><code>         MeanDecreaseAccuracy
schids             15.6591618
sex                 0.1783317
onechi              6.0246583
maedu              -2.1523429
faedu               3.3998484
drunk              -0.7714147
qurel               0.8603566
relation           -0.2970308
desk                3.7265587
net                 3.8550495
dialect             6.4391795
chkhmwk            -1.3450251
chkcouse            0.6845458
classtm            18.8774940
clpre              13.9676480
revitm              9.9829836
subject            13.3015057
know                8.6269976
drsmok             12.4323771
commhr             12.4924669
schtype             2.8600475
schcsrm            15.7482505
comno              15.6795290
bknum              21.0904503
buget              17.9734341
eduqua             18.0905382
fight               6.2511712
brkpb               7.5368073
smok               13.1542247
drink               0.3728828
teainc             29.2559239
money               6.3505110
clfee               9.8453242
qianzi              7.0408610
lifetm              0.7983387
dial                9.3884031
chidia              7.1556550
futcfd             16.3409043
huko                4.9183822
eduy                1.0829673
dangy               1.8206349
houspro             4.5784527</code></pre>
</div>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//Xiao Song.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

