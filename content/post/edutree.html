---
title: "初中生学习成绩的影响因素——基于分类与回归树的方法"
author: ' '
date: '2019-05-08'
slug: edutree
tags: R
categories: R
---



<div class="section level2">
<h2>数据</h2>
<p>本文采用<a href="https://ceps.ruc.edu.cn/">中国教育追踪调查</a> (China Education Panel Survey, CEPS)2013-2014学年基线数据。 采用PPS抽样方法，以人口平均受教育水平和人口比例为分层变量并通过两阶段分层抽样从从全国随机抽取了28个县级单位作为调查点。具体而言，CEPS在每个入样县（区）所辖地理范围内分别抽取4所初中学校。并在每所入样学校中分别抽取4个班级，包括2个七年级班和2个九年级班。</p>
</div>
<div class="section level2">
<h2>模型与算法</h2>
<p>CART算法全称为分类与回归树（Classification and Regression Trees）。它可以处理分类与回归算法，以及生存分析因变量。作为一种非参数的机器学习方法，CART决策树无需对数据的分布做任何假定。CART算法划分数据的依据是变量的取值顺序，因此它对异常值不敏感。最后，通过交叉验证（Cross Validation）的方法求得预测误差。 回归树模型可表示为： <span class="math display">\[f(x) = \sum\limits_{m = 1}^M {{c_m}I(x \in {R_m})} \]</span></p>
<p>其中，<span class="math inline">\(x\)</span>是一系列输入特征（自变量），<span class="math inline">\({R_1},{R_2},...,{R_m}\)</span>是输入空间被划分的M个区域。 是区域<span class="math inline">\({R_m}\)</span>对应的最优值。<span class="math inline">\(I\)</span>代表的是指示函数（indicator function），当输入变量<span class="math inline">\(x\)</span>属于区域 <span class="math inline">\({R_m}\)</span>时，输出为1，否则输出为0。 CART算法选择基尼系数进行属性划分。CART算法可以运用于分类和回归问题中。</p>
</div>
<div class="section level2">
<h2>因变量</h2>
<p>本研究的因变量是被调查学生上一次期中考试的成绩。包括数学成绩、语文成绩、英语成绩。我们将同时对总成绩进行分析。</p>
<p>为了讨论学习成绩的门槛效应，我们将数学成绩是否位于所有学生的前25%(是=1，否=0)单独划分为一个分类变量建立分类树。下图展示的是标准成绩的直方图。</p>
<p><img src="/post/edutree_files/figure-html/add%20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>为了直观地描述不同学校与学习成绩的差异，下面展示了以学校为分组变量，原始数学成绩为因变量的箱线图。</p>
<p><img src="/post/edutree_files/figure-html/a%20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>下面展示的是数学原始成绩是否位于前25%的分类决策树。首先，我们在备选的约50个自变量中纳入学校哑变量。仅考虑家庭、个体、班级因素对学生学习成绩的影响。通过划分训练集和测试集的方式计算模型的预测错误率。检验模型的泛化能力。</p>
<pre class="r"><code>&gt; set.seed(1212323) #设置随机数种子
&gt; sampled &lt;- sample(1:nrow(ceps),nrow(ceps)*0.3,replace=FALSE) #抽取30%样本作为验证集
&gt; test &lt;- ceps[sampled,] #验证集
&gt; train &lt;- ceps[-sampled,] #训练集
&gt; 
&gt; cont &lt;- rpart.control(minsplit=5,maxcompete=100,xval=10,maxdepth=30,cp=0.01) #设置参数
&gt; 
&gt; cltree3 &lt;- rpart(matgreat ~  schids + sex + onechi +  maedu +  faedu + drunk + 
+ qurel + relation + desk + net + dialect + chkhmwk + chkcouse + 
+ classtm +  clpre + revitm + subject + know + drsmok + commhr + 
+ schtype + schcsrm + comno +  bknum + buget + eduqua + fight + 
+ brkpb + smok +  drink +  teainc + money + clfee + qianzi + lifetm +  
+ dial +  chidia +  futcfd +  huko + eduy +  dangy +  houspro ,data = 
+ subset(train,grade9 == 1),weights = sweight,method = &quot;class&quot;,parms = 
+ list(split=&quot;gini&quot;),control=cont,na.action = na.omit,model=T) #决策树
&gt; knitr::kable(printcp(cltree3),caption=&quot;复杂度参数表&quot;,digits =4)</code></pre>
<pre><code>
Classification tree:
rpart(formula = matgreat ~ schids + sex + onechi + maedu + faedu + 
    drunk + qurel + relation + desk + net + dialect + chkhmwk + 
    chkcouse + classtm + clpre + revitm + subject + know + drsmok + 
    commhr + schtype + schcsrm + comno + bknum + buget + eduqua + 
    fight + brkpb + smok + drink + teainc + money + clfee + qianzi + 
    lifetm + dial + chidia + futcfd + huko + eduy + dangy + houspro, 
    data = subset(train, grade9 == 1), weights = sweight, na.action = na.omit, 
    method = &quot;class&quot;, model = T, parms = list(split = &quot;gini&quot;), 
    control = cont)

Variables actually used in tree construction:
 [1] bknum    chidia   chkcouse chkhmwk  classtm  clpre    eduqua  
 [8] eduy     futcfd   lifetm   qianzi   schids   sex      smok    

Root node error: 771957/1527 = 505.54

n=1527 (4937 observations deleted due to missingness)

        CP nsplit rel error  xerror       xstd
1 0.033135      0   1.00000 1.00000 0.00099815
2 0.028470      3   0.90059 0.93843 0.00097583
3 0.016163      5   0.84366 0.89519 0.00095913
4 0.013742      6   0.82749 0.89830 0.00096036
5 0.013573     11   0.75479 0.88627 0.00095558
6 0.012367     13   0.72764 0.87563 0.00095130
7 0.010232     17   0.67817 0.86992 0.00094897
8 0.010166     19   0.65771 0.88209 0.00095390
9 0.010000     20   0.64754 0.88209 0.00095390</code></pre>
<table>
<caption>(#tab:c )复杂度参数表</caption>
<thead>
<tr class="header">
<th align="right">CP</th>
<th align="right">nsplit</th>
<th align="right">rel error</th>
<th align="right">xerror</th>
<th align="right">xstd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.0331</td>
<td align="right">0</td>
<td align="right">1.0000</td>
<td align="right">1.0000</td>
<td align="right">1e-03</td>
</tr>
<tr class="even">
<td align="right">0.0285</td>
<td align="right">3</td>
<td align="right">0.9006</td>
<td align="right">0.9384</td>
<td align="right">1e-03</td>
</tr>
<tr class="odd">
<td align="right">0.0162</td>
<td align="right">5</td>
<td align="right">0.8437</td>
<td align="right">0.8952</td>
<td align="right">1e-03</td>
</tr>
<tr class="even">
<td align="right">0.0137</td>
<td align="right">6</td>
<td align="right">0.8275</td>
<td align="right">0.8983</td>
<td align="right">1e-03</td>
</tr>
<tr class="odd">
<td align="right">0.0136</td>
<td align="right">11</td>
<td align="right">0.7548</td>
<td align="right">0.8863</td>
<td align="right">1e-03</td>
</tr>
<tr class="even">
<td align="right">0.0124</td>
<td align="right">13</td>
<td align="right">0.7276</td>
<td align="right">0.8756</td>
<td align="right">1e-03</td>
</tr>
<tr class="odd">
<td align="right">0.0102</td>
<td align="right">17</td>
<td align="right">0.6782</td>
<td align="right">0.8699</td>
<td align="right">9e-04</td>
</tr>
<tr class="even">
<td align="right">0.0102</td>
<td align="right">19</td>
<td align="right">0.6577</td>
<td align="right">0.8821</td>
<td align="right">1e-03</td>
</tr>
<tr class="odd">
<td align="right">0.0100</td>
<td align="right">20</td>
<td align="right">0.6475</td>
<td align="right">0.8821</td>
<td align="right">1e-03</td>
</tr>
</tbody>
</table>
<pre class="r"><code>&gt; rpart.plot(cltree3)</code></pre>
<div class="figure" style="text-align: center">
<img src="/post/edutree_files/figure-html/c%20-1.png" alt="ROC曲线" width="672" />
<p class="caption">
(#fig:c 1)ROC曲线
</p>
</div>
<pre class="r"><code>&gt; test &lt;- na.omit(test) #删除缺失值
&gt; y.pr &lt;- predict(cltree3,test,type=&quot;prob&quot;) #预测验证集概率
&gt; 
&gt; pr &lt;- y.pr[,2] 
&gt; test &lt;- cbind(test,pr)
&gt; modelroc &lt;- roc(test$matgreat,test$pr)
&gt; plot(modelroc) #ROC 曲线</code></pre>
<div class="figure" style="text-align: center">
<img src="/post/edutree_files/figure-html/c%20-2.png" alt="ROC曲线" width="672" />
<p class="caption">
(#fig:c 2)ROC曲线
</p>
</div>
<pre class="r"><code>&gt; test$yhat &lt;- ifelse(test$pr &gt;0.5,&#39;Yes&#39;,&#39;No&#39;) #大于0.5设置为&quot;是&quot;
&gt; attach(test)
&gt; tab &lt;- table(yhat,matgreat) 
&gt; treeerror &lt;- (sum(tab)-sum(diag(tab)))/sum(tab)
&gt; tab</code></pre>
<pre><code>     matgreat
yhat    0   1
  No  875 183
  Yes 138  85</code></pre>
<pre class="r"><code>&gt; treeerror #验证集错误率</code></pre>
<pre><code>[1] 0.2505855</code></pre>
<pre class="r"><code>&gt; cont &lt;- rpart.control(minsplit=5,maxcompete=100,xval=10,maxdepth=30,cp=0.014) #设置参数
&gt; 
&gt; cltree3 &lt;- rpart(matgreat ~  schids + sex + onechi +  maedu +  faedu + drunk + 
+ qurel + relation + desk + net + dialect + chkhmwk + chkcouse + 
+ classtm +  clpre + revitm + subject + know + drsmok + commhr + 
+ schtype + schcsrm + comno + bknum + buget + eduqua + fight + 
+ brkpb + smok +  drink +  teainc + money + clfee + qianzi + lifetm +  
+ dial +  chidia +  futcfd + huko + eduy + dangy +  houspro ,data = 
+ subset(train,grade9 == 1),weights = sweight,method = &quot;class&quot;,parms = 
+ list(split=&quot;gini&quot;),control=cont,na.action = na.omit) #决策树
&gt; 
&gt; knitr::kable(printcp(cltree3),caption=&quot;复杂度参数表&quot;,digits =4)</code></pre>
<pre><code>
Classification tree:
rpart(formula = matgreat ~ schids + sex + onechi + maedu + faedu + 
    drunk + qurel + relation + desk + net + dialect + chkhmwk + 
    chkcouse + classtm + clpre + revitm + subject + know + drsmok + 
    commhr + schtype + schcsrm + comno + bknum + buget + eduqua + 
    fight + brkpb + smok + drink + teainc + money + clfee + qianzi + 
    lifetm + dial + chidia + futcfd + huko + eduy + dangy + houspro, 
    data = subset(train, grade9 == 1), weights = sweight, na.action = na.omit, 
    method = &quot;class&quot;, parms = list(split = &quot;gini&quot;), control = cont)

Variables actually used in tree construction:
[1] bknum   chidia  classtm smok   

Root node error: 771957/1527 = 505.54

n=1527 (4937 observations deleted due to missingness)

        CP nsplit rel error  xerror       xstd
1 0.033135      0   1.00000 1.00000 0.00099815
2 0.028470      3   0.90059 0.96167 0.00098445
3 0.016163      5   0.84366 0.92616 0.00097118
4 0.014000      6   0.82749 0.97217 0.00098826</code></pre>
<table>
<caption>(#tab:d )复杂度参数表</caption>
<thead>
<tr class="header">
<th align="right">CP</th>
<th align="right">nsplit</th>
<th align="right">rel error</th>
<th align="right">xerror</th>
<th align="right">xstd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.0331</td>
<td align="right">0</td>
<td align="right">1.0000</td>
<td align="right">1.0000</td>
<td align="right">0.001</td>
</tr>
<tr class="even">
<td align="right">0.0285</td>
<td align="right">3</td>
<td align="right">0.9006</td>
<td align="right">0.9617</td>
<td align="right">0.001</td>
</tr>
<tr class="odd">
<td align="right">0.0162</td>
<td align="right">5</td>
<td align="right">0.8437</td>
<td align="right">0.9262</td>
<td align="right">0.001</td>
</tr>
<tr class="even">
<td align="right">0.0140</td>
<td align="right">6</td>
<td align="right">0.8275</td>
<td align="right">0.9722</td>
<td align="right">0.001</td>
</tr>
</tbody>
</table>
<pre class="r"><code>&gt; rpart.plot(cltree3)</code></pre>
<div class="figure" style="text-align: center">
<img src="/post/edutree_files/figure-html/d%20-1.png" alt="ROC曲线" width="672" />
<p class="caption">
(#fig:d 1)ROC曲线
</p>
</div>
<pre class="r"><code>&gt; test &lt;- na.omit(test) #删除缺失值
&gt; y.pr &lt;- predict(cltree3,test,type=&quot;prob&quot;) #预测验证集概率
&gt; 
&gt; pr &lt;- y.pr[,2] 
&gt; test &lt;- cbind(test,pr)
&gt; modelroc &lt;- roc(test$matgreat,test$pr)
&gt; plot(modelroc) #ROC 曲线</code></pre>
<div class="figure" style="text-align: center">
<img src="/post/edutree_files/figure-html/d%20-2.png" alt="ROC曲线" width="672" />
<p class="caption">
(#fig:d 2)ROC曲线
</p>
</div>
<pre class="r"><code>&gt; test$yhat &lt;- ifelse(test$pr &gt;0.5,&#39;Yes&#39;,&#39;No&#39;) #大于0.5设置为&quot;是&quot;
&gt; attach(test)
&gt; tab &lt;- table(yhat,matgreat) 
&gt; treeerror &lt;- (sum(tab)-sum(diag(tab)))/sum(tab)
&gt; tab #混淆矩阵</code></pre>
<pre><code>     matgreat
yhat    0   1
  No  875 183
  Yes 138  85</code></pre>
<pre class="r"><code>&gt; treeerror #验证集错误率</code></pre>
<pre><code>[1] 0.2505855</code></pre>
<p>可以发现，对因变量分类有显著贡献的变量有学校哑变量、对孩子未来的信心、上兴趣班费用总计、与学生交流时间。可见学校层面的特征对数学成绩的影响非常强。</p>
<p>在初次拟合分类树之后，我们对分类树进行剪枝。通过第一棵分类树的结果，我们选取预测误差(即表中的xerror通过交叉验证获得)最小的CP值带入到下一个模型中，最终的验证集错误率在25%左右。</p>
</div>
