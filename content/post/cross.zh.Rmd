---
title: "交叉验证"
author: ' '
date: '2019-05-25'
slug: cross
tags: ["R","应用统计","机器学习"]
output:
  html_document:
    toc: true
    theme: united
---


# 基本概念

交叉验证是机器学习中的常用模型选择方法。其中最常用的方法是K折交叉验证(k-fold cross validation)。K折交叉验证重复使用数据，把给定的数据切分为K个互斥子集，每次使用1个子集作为测试集，使用余下k-1个子集的并集作为训练集。其中，训练集用于模型的训练，测试集用于模型的评估和选择。在样本量不够充足的情况下，交叉验证法通过重复使用数据能够减少样本划分不同导致的差别，并且选择测试误差最小的模型，增强模型的泛化能力。


交叉验证主要有以下种类：

+ 简单交叉验证 (hold-out cross validation)

+ k折交叉验证 (K-fold cross-validation)

+ 留一交叉验证(leave-one-out cross validation)

谢益辉的统计动画R包[animation](https://yihui.name/animation/example/cv-ani/)直观地展示了交叉验证方法。

```{r 1,comment = NA,warning = F,message = F, include = T,fig.align='center'}
#install.packages('mlbench')
library(caret) #加载数据集
```

# R示例

## 10折交叉验证 (K-fold cross-validation)
```{r 2,comment = NA,warning = F,message = F, include = T,fig.align='center'}
#install.packages('mlbench')

rfControl <-trainControl( #10折交叉验证
method ="cv", 
number =10 # Number of folds
)

library(mlbench) #加载数据集
data(BostonHousing)
head(BostonHousing)
nrow(BostonHousing) #样本量

rpartFit <- train(medv ~ .,
                  data = BostonHousing,
                  method = "rpart",
                  trControl = rfControl)
rpartFit
```

将数据集D划分为K个子集同样存在多种划分方式。为减小因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p 次k折交叉验证结果的均值， 例如常见的有"10次10 折交叉验证"。


```{r cv,comment = NA,warning = F,message = F, include = T,fig.align='center',out.width='70%',fig.asp=1.2} 
repeatedcv <-trainControl(method ="repeatedcv", number =10,repeats =10, savePredictions
=TRUE)
rpartFit <- train(medv ~ .,
                  data = BostonHousing,
                  method = "rpart",
                  trControl = repeatedcv)
rpartFit

importance <- varImp(rpartFit, scale = F)
# 得到各个变量的重要性
plot(importance, xlab = "变量重要性")
```






## 留一交叉验证(leave-one-out cross validation)
```{r 3,comment = NA,warning = F,message = F, include = T,fig.align='center'}
rfControl <-trainControl(
method ="LOOCV"
) #留一交叉验证
rpartFit <- train(medv ~ .,
                  data = BostonHousing,
                  method = "rpart",
                  trControl = rfControl)
rpartFit
#summary(rpartFit)
varImp(rpartFit, scale = F)
# 得到各个变量的重要性
```

+ 我们发现个别变量对于预测完全没有帮助，故可以将这些变量在之后的分析中删除。

# 使用`caret`包训练K近邻模型

 + 数据：[口袋妖怪](https://www.kaggle.com/abcsds/pokemon)数据集
 + 任务：通过各种属性预测神奇宝贝是否为传说级别
 
>1. ID,每只神奇宝贝的ID  
2. Name,每只神奇宝贝的名字  
3. Type1:每只神奇宝贝的类型，比如说水系，比如说火系  
4. Type2:由于有特殊的神奇宝贝拥有复数以上的属性。  
5. Total:指每只神奇宝贝的强度，一般越高越强  
6. HP：指每只神奇宝贝的生命值  
7. Attack:指每只神奇宝贝的攻击力  
8. Defense:指每只神奇宝贝的防御力  
9. SP Attack:指每只神奇宝贝面对相克属性神奇宝贝时的攻击力，通常会比普通攻击力高  
10. SP Defense:指每只神奇宝贝面对相克属性神奇宝贝时的防御力，通常会比普通防御力高。  
11. Speed:指每只神奇宝贝的速度  
12. Generation：指每一只神奇宝贝属于哪一部神奇宝贝的，目前分为五部。 
13. Legendary:指每一只神奇宝贝是不是属于传说级别的神奇宝贝，比如麒麟，超梦，梦幻之类的。  

```{r 4,comment = NA,warning = F,message = F, include = T,fig.align='center'}
library(readr)
library(caret)
library(kknn)
pokemon <- read_csv("E:/R_codes/others/Pokemon.csv")
duindex <- duplicated(pokemon$id)
#用!来取反
pokemon <- pokemon[!duindex,]
pokemon$Legendary <- as.factor(pokemon$Legendary)
pokemon <- na.omit(pokemon)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)

pokemon <- na.omit(pokemon)

set.seed(3333)
knn_fit <- train(Legendary ~ Type1 + Type2 + Total+ HP + Defense+ Attack + Speed + Generation, data = pokemon, method = "knn",
 trControl=trctrl,
 preProcess = c("center", "scale"),
 tuneLength = 10)
knn_fit

```














