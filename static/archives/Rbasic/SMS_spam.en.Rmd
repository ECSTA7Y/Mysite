---
title: SMS spam text classification
author:  
date: 2019/12/1
output:
  bookdown::html_document2:
    toc: true
    theme: readable
---

[Text-Classification](https://cfss.uchicago.edu/notes/supervised-text-classification/)

```{r, include=F}
knitr::opts_chunk$set(comment=NA,error=T,message = F,warning = F,fig.align='center',out.width ='90%')
```

# 首先...

使用`read_csv`读取数据后无需使用`tibble`函数转化。`read_csv`能够直接得到`tibble`对象。不然会报错。

R在构建文档-词语矩阵的有许多实现方式。下面使用了`tm::DocumentTermMatrix`函数实现。在此之前，我尝试了`quanteda::dfm_weight`函数，但是在我的本地R软件中总是报错（在Kaggle上的R Notebook能够运行）。另一个可能的路径是使用`tidytext::unnest_tokens`等函数进行去除停止词、去除数字和标点符号、提取词干等一系列操作；再通过`tidytext::cast_dtm`转化成`DocumentTermMatrix`对象。但这么做会导致因变量和特征矩阵行数不一致的问题。由于我无法解决它，我采用了下面的方案。当然使用Python是非常好的选择，我在[这里](https://www.kaggle.com/rikdifos/sms-text-classification)给出了基于Python的做法。相比R，Python的可视化能力略显不足。

我认为`tidytext`十分适合对文本信息进行探索和可视化，而`tm`则适合构建矩阵进行建模。如果将二者混用则可能导致问题。

# 上代码

```{r}
library(magrittr)
library(quanteda)
library(tidytext)
library(ggplot2)
library(dplyr)
library(tm)
library(readr)
library(stringr)
```

```{r}
sms <- read_csv("E:/MaLearning/SPAM text message 20170820 - Data.csv")
```

原数据共两列，其中一列记录了是否为垃圾短信的标签。另一列是短信文本内容。其中，非垃圾邮件的比例约为`r  round(prop.table(table(sms$Category))[1],2)`，垃圾邮件的比例为`r  round(prop.table(table(sms$Category))[2],2)`。

```{r}
sms %>% count(Category)
#sms %$% prop.table(table(Category))[1]
```


数据概览如下：

```{r}
smswd <- sms %>%
  rename(message = Message,tag=Category) %>% 
  mutate(ID = row_number())
head(smswd)
Y <- as.factor(smswd$tag)
```


```{r}
smswd$message <- lapply(smswd$message , iconv, "UTF-8", "ASCII", sub="")

smsvis <- smswd %>%
  unnest_tokens(word,message) %>%
  filter(!str_detect(word, "^[0-9]*$")) %>%
  anti_join(stop_words) %>% 
  mutate(word = SnowballC::wordStem(word,language = "english"))
head(smsvis)

library(reshape2)
library(wordcloud)
smsvis %>%
  count(word, tag, sort = T) %>%
  acast(word ~ tag, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("blue", "red"),max.words = 50)

smsvis %>%
  count(tag, word) %>%
  group_by(tag) %>%
  top_n(15) %>%
  ggplot() +
  geom_col(aes(reorder(word, n), 
               n, fill = tag),
           show.legend = F) +
  facet_wrap(~tag, scales = "free_y") +
  coord_flip()

smsvis %>%
  count(tag, word) %>%
  bind_tf_idf(word,tag,n) %>% 
  group_by(tag) %>%
  top_n(10) %>%
ggplot() + 
  geom_col(aes(reorder(word,tf_idf), 
             tf_idf, fill = tag),
           show.legend = F) +
  facet_wrap(~tag, scales = "free_y") +
  coord_flip()



```


```{r}

ms_corpus <- VCorpus(VectorSource(smswd$message))

sms_dtm <- DocumentTermMatrix(ms_corpus, control =
                                 list(tolower = T,
                                      removeNumbers = T,
                                      stopwords = T,
                                      removePunctuation = T,
                                      stemming = T))

dim(sms_dtm) #5572

sms_dtm1 <- removeSparseTerms(sms_dtm, sparse = .98)
smsmat <- as.matrix(sms_dtm1)
#head(smsmat)
dim(smsmat)
```

原本的文档-词语频率矩阵有`r dim(sms_dtm)[2]`个特征，维度过高且过于稀疏。经过`removeSparseTerms`函数处理后保留了`r dim(smsmat)[2]`个特征。

# 算法

朴素贝叶斯常常被用作文本分类的基线模型。因为文本数据满足每个单词相互独立。而且，一个单词的位置不依赖于另一个单词。也就是说，用于建模的文档-词语频率矩阵(DTM)各列独立，这满足了朴素贝叶斯的独立性假设。此外，为了提高准确率，我还进一步使用了支持向量机方法。

```{r}
library(caret)
library(e1071)
svmc <- svm(smsmat, Y)
print(svmc)
summary(svmc)
pred <- predict(svmc,smsmat)
#confusionMatrix(pred,Y,positive ='spam',mode="prec_recall")
conMatrix <- confusionMatrix(pred,Y,
                             positive ='spam',
                             mode="prec_recall") 
conMatrix[["table"]]


nb <- naiveBayes(smsmat, Y) # klaR包也能够实现NaiveBayes.

#setwd('F:/Mysite/Mysite/static/archives/Rbasic')
#saveRDS(nb, "naiveBayes.rds")
#save(nb,"naiveBayes.RData")
##下次需要使用时
#load("naiveBayes.RData")
#print(nb)
#summary(nb)
pred1 <- predict(nb,smsmat)

conMatrix1 <- confusionMatrix(pred1,Y,
                              positive ='spam',
                              mode="prec_recall") 
#混淆矩阵
conMatrix1[["table"]]

prop.table(conMatrix1[["table"]],1)
```

支持向量机算法的准确率为`r round(conMatrix[["overall"]][["Accuracy"]],2)`，平衡准确率为`r round(conMatrix[["byClass"]][["Balanced Accuracy"]],2)`。

朴素贝叶斯算法的准确率为`r round(conMatrix1[["overall"]][["Accuracy"]],2)`，平衡准确率为`r round(conMatrix1[["byClass"]][["Balanced Accuracy"]],2)`。

编写一个对混淆矩阵进行可视化的函数：

```{r,fig.asp=0.8}
plot_table <- function(x,xlab='Predicted label',
                       ylab='True label',
                       normalize = F){
  if(normalize){
    x <- round(prop.table(x,1), 2)
    mar <- as.data.frame(x)
  }
  else{
    mar <- as.data.frame(x)
  }
  ggplot2::ggplot(mar,aes(mar[,2],mar[,1])) +
    geom_tile(aes(fill=Freq),color='black') +
    scale_fill_gradientn(colours = c('gray98',
                                     'steelblue1',
                                     'midnightblue'))+
    geom_label(aes(label = Freq)) +
     labs(fill='',x=xlab,y=ylab) +
     ylim(rev(levels(mar[,2])))+
     scale_y_discrete(expand=c(0,0))+
     scale_x_discrete(expand=c(0,0))
}

plot_table(conMatrix1[["table"]],'Reference','Prediction')+
  theme_bw()

plot_table(conMatrix1[["table"]])+
  theme_bw()

plot_table(conMatrix1[["table"]],'Reference','Prediction',normalize=T)+
  theme_bw()
```

抛开准确率问题不谈，这里有另一个问题，为了避免不必要的损失，大部分人更希望过滤系统尽可能不要把有用的信息删掉。也就是说：

>宁可放过一千也不要错杀一个。

所以，对于这个任务来说，算法的精确率越高越好，召回率(或者说查全率)越低越好。根据混淆矩阵，SVM的召回率为`r round(conMatrix[["byClass"]][["Recall"]],2)`，朴素贝叶斯的召回率为`r round(conMatrix1[["byClass"]][["Recall"]],2)`。SVM的精确率为`r round(conMatrix[["byClass"]][["Precision"]],2)`，朴素贝叶斯的精确率为`r round(conMatrix1[["byClass"]][["Precision"]],2)`。从混淆矩阵中我们也能看出，朴素贝叶斯算法将更多普通短信归类于垃圾短信了。因此SVM显然是更佳的模型。

# 应用

下面我们用自己输入的短信文本放入朴素贝叶斯模型进行评价。同样，我们编写一个函数，输入短信字符串，输出判别结果。


```{r}
new <- 'please go home at 4 o clock bro' 

new2 <- 'We are trying to contact you.Please call our customer service representative on FREEPHONE.Claim code S89. Valid 12hrs only'

test_result <- function(model,string){
  ms_corpus <- VCorpus(VectorSource(string))
test_dtm <- DocumentTermMatrix(ms_corpus, control =
                                 list(tolower = T,
                                      removeNumbers = T,
                                      stopwords = T,
                                      removePunctuation = T,
                                      stemming = T))
test_dtmx <- as.matrix(test_dtm)
result <- predict(model,test_dtmx)
return(result)
}



test_result(nb,new)
test_result(nb,new2)
```

经过检验，支持向量机不能支持新数据的预测。如果新的测试集的变量超出了训练集的变量，就无法运行。而朴素贝叶斯可以(我没弄清楚为什么)，所以我们可以使用训练好的模型任意输入新的短信文本进行判断。

另外，为了更好地分享短信过滤程序，我将训练好的朴素贝叶斯模型保存下来并编写成Shiny App。使得用户输入任意短信文本就能在用户友好的图形界面的得到判定结果。用户可以点击[这里](https://github.com/ECSTA7Y/txtnb)查看Shiny App的源代码。你也可以在本地的R中输入以下代码下载并运行这个程序：

```r
library(shiny)
runGitHub( "txtnb", "ECSTA7Y")

```










```{r,eval=F,include=F}
smswddm

inspect(smswddm)

smswddm<- removeSparseTerms(smswddm, sparse=0.985)

inspect(smswddm)
smswddm
smswddm <- as.matrix(smswddm)
head(smswddm)

library(e1071)
model <- svm(smswddm, Y)
print(model)
summary(model)
library(tm)
library(Matrix)
smswddm <- smswd %>% 
   count(ID,word) %>% 
   cast_sparse(ID,word,n)

docvars(sms.corpus, "Category") <- data$Category

spam.plot <- corpus_subset(sms.corpus, docvar1 == "spam")  
spam.plot <- dfm(spam.plot, tolower = TRUE, remove_punct = TRUE, remove_twitter = TRUE, remove_numbers = TRUE, remove=stopwords("SMART"))
spam.col <- brewer.pal(10, "BrBG")  

spam.cloud <- textplot_wordcloud(spam.plot, min.freq = 16, color = spam.col)  
title("Spam Wordcloud", col.main = "grey14")  

ham.plot <- corpus_subset(sms.corpus, docvar1 == "ham")  
ham.plot <- dfm(ham.plot, tolower = TRUE, removePunct = TRUE, removeTwitter = TRUE, removeNumbers = TRUE, remove=c("gt", "lt", stopwords("SMART")))  
ham.col <- brewer.pal(10, "BrBG")  
textplot_wordcloud(ham.plot, min.freq = 50, colors = ham.col, fixed.asp = TRUE)  
title("Ham Wordcloud", col.main = "grey14")


```
```{r,eval=F,include=F}
sms.dfm <- dfm(sms.corpus, tolower = TRUE)  
sms.dfm <- dfm_trim(sms.dfm, min_count = 5, min_docfreq = 3)  
sms.dfm <- dfm_weight(sms.dfm, type = "tfidf")  

sms.raw.train <- raw.data[1:4738,]  
sms.raw.test <- raw.data[4739:nrow(raw.data),]


sms.dfm.train <- sms.dfm[1:4738,]  
sms.dfm.test <- sms.dfm[4739:nrow(raw.data),]  
sms.classifier <- textmodel_nb(sms.dfm.train, sms.raw.train$Category)  


sms.predictions <- predict(sms.classifier, newdata = sms.dfm.test)  
table(sms.predictions$nb.predicted, sms.raw.test$Category)  
```

