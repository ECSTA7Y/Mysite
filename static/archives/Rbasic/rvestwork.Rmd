---
title: 'rvest爬虫'
author: ' '
date: '2019-05-25'
slug: cross 
output:
  bookdown::html_document2:
    toc: true
    theme: readable
---


```{r,include=F}
knitr::opts_chunk$set(comment=NA,error=T,message=F,warning=F,fig.align='center',out.width='90%')
```


```{r}
library(rvest)
library(magrittr)
library(xml2)
library(selectr)#解析器,少了这个包，后面会报错
library(stringr)

get_text = function(url,w){ # 读取特定html节点的函数
text = url %>%
  read_html() %>% 
  html_nodes(.,w) %>% 
  html_text()
return(text)
}

# 测试
#get_text("https://xsong.ltd/zh/pybasic/",'h1')

```


```{r}
library(stringr)
txturl = ''
for (i in 1:20){
  c = 'https://d.cosx.org/all?page='
  url = str_c(c,i,sep='')
  Sys.sleep(15) # 避免被反爬虫，每次循环暂停15秒
  getext = get_text(url,'a')
  txturl = c(txturl,getext)
}
head(txturl,10)

```


```{r}
txturl = txturl %>% 
  str_replace_all(.,' ','') %>% 
  str_replace_all(.,'\n','')
  
# 去除带有'上一页'等字样的字符
txturl = txturl[!str_detect(txturl, '上一页')]
txturl = txturl[!str_detect(txturl, '下一页')] 

head(txturl,10)
```

```{r}
library(dplyr)
library(stringr)

long = str_length(txturl)
cosdf = tibble(cap = txturl,long = long)
cosdf

cosdf = cosdf %>% filter(long!=0)
dim(cosdf)

svlong = cosdf %>% select(long) 
svlong
setwd('C:/Users/xsong/Desktop/table')
#saveRDS(svlong, "svlong.rds")
#saveRDS(cosdf, "cosdf.rds")

library(ggplot2)
ggplot(svlong,aes(long,..density..))+
  geom_histogram(col='black',
                 fill = 'white')+
  geom_density(alpha=.2,
               fill="#FF6666") 


```

